---
title: 'Weekly Exercises #6'
author: "Kai Yamanishi"
output: 
  html_document:
    keep_md: TRUE
    toc: TRUE
    toc_float: TRUE
    df_print: paged
    code_download: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error=TRUE, message=FALSE, warning=FALSE)
```

```{r libraries}
library(tidyverse)     # for data cleaning and plotting
library(gardenR)       # for Lisa's garden data
library(lubridate)     # for date manipulation
library(openintro)     # for the abbr2state() function
library(palmerpenguins)# for Palmer penguin data
library(maps)          # for map data
library(ggmap)         # for mapping points on maps
library(gplots)        # for col2hex() function
library(RColorBrewer)  # for color palettes
library(sf)            # for working with spatial data
library(leaflet)       # for highly customizable mapping
library(ggthemes)      # for more themes (including theme_map())
library(plotly)        # for the ggplotly() - basic interactivity
library(gganimate)     # for adding animation layers to ggplots
library(gifski)        # for creating the gif (don't need to load this library every time,but need it installed)
library(transformr)    # for "tweening" (gganimate)
library(shiny)         # for creating interactive apps
library(patchwork)     # for nicely combining ggplot2 graphs  
library(gt)            # for creating nice tables
library(rvest)         # for scraping data
library(robotstxt)     # for checking if you can scrape data
theme_set(theme_minimal())
```

```{r data}
# Lisa's garden data
data("garden_harvest")

#COVID-19 data from the New York Times
covid19 <- read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")

```

## Put your homework on GitHub!

Github Link: https://github.com/RosnGuild/Exercise-6

Go [here](https://github.com/llendway/github_for_collaboration/blob/master/github_for_collaboration.md) or to previous homework to remind yourself how to get set up. 

Once your repository is created, you should always open your **project** rather than just opening an .Rmd file. You can do that by either clicking on the .Rproj file in your repository folder on your computer. Or, by going to the upper right hand corner in R Studio and clicking the arrow next to where it says Project: (None). You should see your project come up in that list if you've used it recently. You could also go to File --> Open Project and navigate to your .Rproj file. 

## Instructions

* Put your name at the top of the document. 

* **For ALL graphs, you should include appropriate labels.** 

* Feel free to change the default theme, which I currently have set to `theme_minimal()`. 

* Use good coding practice. Read the short sections on good code with [pipes](https://style.tidyverse.org/pipes.html) and [ggplot2](https://style.tidyverse.org/ggplot2.html). **This is part of your grade!**

* **NEW!!** With animated graphs, add `eval=FALSE` to the code chunk that creates the animation and saves it using `anim_save()`. Add another code chunk to reread the gif back into the file. See the [tutorial](https://animation-and-interactivity-in-r.netlify.app/) for help. 

* When you are finished with ALL the exercises, uncomment the options at the top so your document looks nicer. Don't do it before then, or else you might miss some important warnings and messages.


## Warm-up exercises from tutorial

1. Read in the fake garden harvest data. Find the data [here](https://github.com/llendway/scraping_etc/blob/main/2020_harvest.csv) and click on the `Raw` button to get a direct link to the data. After reading in the data, do one of the quick checks mentioned in the tutorial.
  
```{r}
garden_fake <- read_csv("https://raw.githubusercontent.com/llendway/scraping_etc/main/2020_harvest.csv")
```
  
2. Read in this [data](https://www.kaggle.com/heeraldedhia/groceries-dataset) from the kaggle website. You will need to download the data first. Save it to your project/repo folder. Do some quick checks of the data to assure it has been read in appropriately.

```{r}
groceries <- read_csv("Groceries_dataset.csv") 

groceries %>% 
  mutate(across(where(is.character), as.factor)) %>% 
  summary()
```

3. Create a table using `gt` with data from your project or from the `garden_harvest` data if your project data aren't ready. Use at least 3 `gt()` functions.

```{r}
garden_harvest %>% 
  filter(week(date) == 35) %>% 
  group_by(vegetable, date) %>% 
  summarise(date, weight = sum(weight), units) %>% 
  ungroup() %>% 
  unique() %>% 
  gt(rowname_col = "vegetable", 
     groupname_col = "date") %>% 
  fmt_date(
    columns = c(date),
    date_style = 7) %>% 
  tab_header(
    title = "Week 35 Harvest",
    subtitle = "Uses the garden_harvest dataset") %>% 
  tab_options(column_labels.background.color = "darkgreen")
  
  
```
  
5. Use `patchwork` operators and functions to combine at least two graphs using your project data or `garden_harvest` data if your project data aren't read.

```{r}
harvest_weight <- garden_harvest %>% 
  group_by(date) %>% 
  summarise(weight = sum(weight)) %>% 
  ggplot(aes(x = date, y = weight)) +
  geom_line() +
  labs(x = "", y = "", title = "Daily Grams Harvested")

vegetable_harvested <- garden_harvest %>% 
  group_by(date, vegetable) %>% 
  summarise() %>% 
  summarise(num_veg = n()) %>% 
  ggplot(aes(x = date, y = num_veg)) +
  geom_line() +
  labs(x = "", y = "", title = "Daily Unique Vegetables Harvested")

harvest_weight + vegetable_harvested
  
```
  
## Webscraping exercise (also from tutorial)

Use the data from the [Macalester Registrar's Fall 2017 Class Schedule](https://www.macalester.edu/registrar/schedules/2017fall/class-schedule/#crs10008) to complete all these exercises.

6. Find the correct selectors for the following fields. Make sure that each matches 762 results:

  * Course Number
  * Course Name
  * Day
  * Time
  * Room
  * Instructor
  * Avail. / Max
  * General Education Requirements (make sure you only match 762; beware of the Mac copyright banner at the bottom of the page!)
  * Description

Then, put all this information into one dataset (tibble or data.frame) Do not include any extraneous information like "Instructor: ".

```{r}
fall2017 <- read_html("https://www.macalester.edu/registrar/schedules/2017fall/class-schedule/#crs10008")

scrape_col <- function(html, element, cutoff = 0) {
  html %>% 
  html_elements(element) %>%
  html_text2() %>% 
  str_sub(start = cutoff)
}

course_number <- scrape_col(fall2017, ".class-schedule-course-number")
course_title <- scrape_col(fall2017, ".class-schedule-course-title")
course_day <- scrape_col(fall2017, "td.class-schedule-label:nth-child(3)", 7)
course_time <- scrape_col(fall2017, "td.class-schedule-label:nth-child(4)", 7)
course_room <- scrape_col(fall2017, "td.class-schedule-label:nth-child(5)", 7)
course_instructor <- scrape_col(fall2017, "td.class-schedule-label:nth-child(6)", 13) 
course_availability <- scrape_col(fall2017, "td.class-schedule-label:nth-child(7)", 14) 
course_description <- scrape_col(fall2017, "td.class-schedule-notes")

fall_2017 <- tibble(course_number, 
       course_title, 
       course_day, 
       course_time, 
       course_room, 
       course_instructor, 
       course_availability, 
       course_description)
```

7. Create a graph that shows the number of sections offered per department. Hint: The department is a substring of the course number - there are `str_XXX()` functions that can help. Yes, COMP and MATH are the same department, but for this exercise you can just show the results by four letter department code, e.g., with COMP and MATH separate.

```{r, fig.width=10, fig.height=8, fig.alt="Total number of courses offered by each department for fall semester, 2017."}
fall_2017 %>% 
  summarise(department = str_sub(course_number, end = 4)) %>% 
  group_by(department) %>% 
  summarise(total_courses = n()) %>% 
  filter(str_starts(department, "PE ") != TRUE) %>% 
  ggplot(aes(x = total_courses, y = fct_reorder(department, total_courses))) + 
  geom_bar(stat = "identity") +
  labs(title = "Number of Courses Offered by Each Department, Fall 2017", x = "", y = "")
```


8. Analyze the typical length of course names by department. To do so, create a new data table based on your courses data table, with the following changes:

```{r, fig.width=10, fig.height=8, fig.alt="Average length in characters of Course Titles and Descriptions by Department at Macalester College, Fall 2017"}
fall_2017_8 <- fall_2017 %>% 
  mutate(title_length = str_length(course_title), 
         description_length = str_length(course_description), 
         course_department = str_sub(course_number, end = 4)) %>% 
  group_by(course_department) %>% 
  filter(n() >= 10) %>% 
  mutate(avg_title_length = mean(title_length), avg_description_length = mean(description_length)) %>% 
  ungroup()

one <- fall_2017_8 %>% 
  ggplot(aes()) +
  geom_point(aes(x = title_length, 
                 y = fct_reorder(course_department, avg_title_length))) +
  geom_point(aes(x = avg_title_length, 
                 y = fct_reorder(course_department, avg_title_length)), 
             colour = "red", 
             size = 2) +
  labs(title = "Average Course Title Length by Department", 
       x = "Characters", 
       y = "")

two <- fall_2017_8 %>% 
  ggplot(aes()) +
  geom_point(aes(x = description_length, 
                 y = fct_reorder(course_department, avg_description_length))) +
  geom_point(aes(x = avg_description_length, 
                 y = fct_reorder(course_department, avg_description_length)), 
             colour = "red", 
             size = 2) +
  labs(title = "Average Course Description Length by Department", 
       x = "Characters", 
       y = "")

one + two
```
  
  * New columns for the length of the title of a course and the length of the description of the course. Hint: `str_length`.  
  * Remove departments that have fewer than 10 sections of courses. To do so, group by department, then remove observations in groups with fewer than 10 sections (Hint: use filter with n()). Then `ungroup()` the data.  
  * Create a visualization of the differences across groups in lengths of course names or course descriptions. Think carefully about the visualization you should be using!


  

**DID YOU REMEMBER TO UNCOMMENT THE OPTIONS AT THE TOP?**
